---
title: "Caring and Feeding the Wild Caught Data"
subtitle: "A Case of The NLSY79 Data"
authors:
  - name: Dewi Amaliah
    thanks: ""
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: ""
  - name: Kate Hyde
    thanks: ""
    department: ""
    affiliation: ""
    location: ""
    email: ""
  - name: Emi Tanaka
    thanks: emitanaka.org
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: emi.tanaka@monash.edu
  - name: Nicholas Tierney
    thanks: ""
    department: ""
    affiliation: ""
    location: ""
    email: ""
  - name: Dianne Cook
    thanks: dicook.org
    department: Department of Econometrics and Business Statistics
    affiliation: Monash University
    location: Clayton, VIC 3800
    email: dicook@monash.edu
bibliography: references.bib
biblio-style: unsrt
#preamble: >
output: 
  rticles::arxiv_article:
    keep_tex: false
date: "24/02/2021"
always_allow_html: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE, 
                      message = FALSE,
                      cache = TRUE, 
                      cache.path = "cache/",
                      fig.path = "figures/")
library(tidyverse)
library(brolgar)
library(patchwork)
library(kableExtra)
library(MASS)
library(janitor)
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)
library(knitr)
library(webshot)
```

# Introduction

The idea of "Open Data" is that the data are freely accessible, modified, and shared by anyone for any purpose [@opendata]. Due too its openness, Open Data are sometimes used and modified to be incorporated as the data in statistical text book or in research. Despite its traits, open data often have an issue with its quality in the sense that it is often not tidy and clean. Hence, it should be tidied and cleaned before further analysis to prevent inappropriate usage of statistical method that may lead to a misleading result [@HuebnerMariannePhD2016Asat]. 

@HuebnerMariannePhD2016Asat also argued that data tidying and cleaning is the first part of Initial Data Analysis (IDA). The second and third steps are to explore the data properties and to document and report the process for the later formal analysis. This second step is the same with Chatfield's perspective on the goal of IDA [@Chatfield1985TIEo], which is to get the "feel" of the data. In other word, IDA could be regarded as a way to assess the data quality. 

@DasuTamraparni2003Edma mentioned that data cleaning and exploration, which is the IDA notion, is a difficult task and determine 80 percent of the data mining result. Despite its importance, this stage is often undervalued and neglected [@Chatfield1985TIEo]. @WickhamHadley2014TD also stated that there has been few research of the good practice of data cleaning. Furthermore, the decisions made in this stage is often unreported  in term that the IDA are often performed in an unplanned and unstructured way and is only shared among restricted party [@HuebnerMarianne2020Haar]. Furthermore, documenting the result of IDA is utterly essential as the information preservation for the downstream statistical analyses and model building [@HuebnerMariannePhD2016Asat] and to avoid publication bias [@HuebnerMarianne2020Haar].

This paper aims to demonstrate the steps of IDA, which is tidying, cleaning, and documenting the data. We used the longitudinal data from the National Longitudinal Survey of Youth 1979 (NLSY79) or is known as the NLSY79. Particularly, we are interested in doing the IDA to the wages and several demographic variables of the NLSY79 cohort whose highest grade are up to 12th grade and the high school dropouts.  

We chose the NLSY79 data because this data play an important role in research in various discipline including economics, sociology, education, public policy, and public health for more than a quarter of the century [@MichaelRPergamit2001DWTN]. In addition, The National Longitudinal Survey is considered as survey with high retention rates and carefully designed making it suitable for a life course research [@MichaelRPergamit2001DWTN] and [@eliznlsy]. According to @eliznlsy as of 2015, thousand of articles, and hundreds of book chapters and monographs has incorporated the NLSY79 data. Moreover, the NLSY79 is considered as the most widely used and most important cohort in the NLSY79 data sets [@MichaelRPergamit2001DWTN].


# The NLSY79

The NLSY79 is a longitudinal survey held by the U.S Bureau of Labor Statistics that follows the lives of a sample of American youth and born between 1957-1964. The cohort originally included 12,686 respondents ages 14-22 when first interviewed in 1979. It was comprised of Blacks, Hispanics, economically disadvantaged non-Black non-Hispanics, and youth in the military. In 1984 and 1990, two sub-samples were dropped from the interview; the dropped subjects are the 1,079 members of the military sample and 1,643 members of the economically disadvantaged non-Black non-Hispanics respectively. Hence, 9,964 respondents remain in the eligible samples. The surveys were conducted annually from 1979 to 1994 and biennially thereafter. Data are now available from Round 1 (1979 survey year) to Round 28 (2018 survey year).

Although the main focus area of the NLSY is labor and employment, the NLSY also cover several other topics including education; training and achievement; household, geography and contextual variables; dating, marriage, cohabitation; sexual activity, pregnancy, and fertility; children; income, assets and program participation; health; attitudes and expectations; and crime and substance use. 

There are two ways to conduct the interview of the NLSY79, which are face to face interview or by telephone. In recent survey years, more than 90 percent of respondents were interviewed by telephone [@eliznlsy]. 

# The NLSY79 Data Cleaning 

## Getting and Tidying the Data

The NLSY79 data are stored in a [database](https://www.nlsinfo.org/content/cohorts/nlsy79/get-data) and could be downloaded by variables. Several variables are available for download and could be browsed by index. For the wages data set, we only extracted these variables:

- Education, Training & Achievement Scores
    -  Education -> Summary measures -> All schools -> By year -> Highest grade completed
       - Downloaded all of the 78 variables in Highest grade completed.
- Employment
    - Summary measures -> By job -> Hours worked and Hourly wages
      - Downloaded all of the 427 variables in Hours worked
      - Downloaded all of the 151 variables in Hourly wages
      
      Both hours worked and hourly wages are recorded by the job, up to five jobs for each id/subject. 
- Household, Geography & Contextual Variables
    - Context -> Summary measures -> Basic demographics 
      - Downloaded year and month of birth, race, and sex variables.
      
      There are two versions of the year and month of birth, i.e. 1979 and 1981 data. We downloaded these two versions.
      
The downloaded data set came in a csv (NLSY79.csv) and dat (NLSY79.dat) format. We only used the .dat format. It also came along with these files:

- NLSY79.NLSY79: This is the tagset of variables that can be uploaded to the web site to recreate the data set.
- NLSY79.R: This is an R script provided automatically by the database for reading the data into R and convert the variables' name and its label into something more sensible. We utilized this code to do an initial data tidying. It produced two data set,  `categories_qnames` (the observations are stored in categorical/interval values) and `new_data_qnames` (the observations are stored in integer form).

```{r, cache = TRUE}
source(here::here("data-raw/NLSY79/NLSY79.R"))
```

According to @WickhamHadley2014TD, a tidy data sets comply with three rules, the first is that each variable forms a column, the second is that each observation forms a row, and the last is that each type of observational unit forms a table. Unfortunately, the `new_data_qnames` did not meet these requirements in the way that the value for particular year and job are stored in different columns, hence the data contains a huge number of columns (686 columns). The example of the untidy of the data set is displayed in Table \ref{tab:untidy-data}, which actually intended to display the hourly rate of each respondent by job (HRP1 to HRP5) and by year (1979 and 1980). The table implies that the column headers are values of the year and job, not variable names. 

```{r untidy-data, echo = FALSE}

untidy_demo <- new_data_qnames %>%
  as_tibble() %>%
  # in 2018, the variable's name is Q3-4_2018, instead of HGC_2018
  rename(HGC_2018 = `Q3-4_2018`) %>%
  dplyr::select(CASEID_1979,
            starts_with("HRP") &
              ends_with(c("1979", "1980", "1981", "1982", "1983"))) %>%
  dplyr::select(1:7) %>%
  head()

kable(untidy_demo,
      caption = "The Untidy Form of the NLSY79 Raw Data") %>%
  kable_styling(latex_options = "striped")
```

Consequently, the data should be tidied and wrangled first to extract the demographic and employment variables that we want to put in the final data set. We mainly used `tidyr` [@tidyr], `dplyr` [@dplyr], and `stringr` [@stringr] to do this job.

### Tidying demographic variables

`Age in 1979`, `gender`, `race`, `highest grade completed` (factor and integer), and the `year when the highest grade completed` are the variables that we want to use in the cleaned data set. 

Age in 1979 are derived from year of birth and month of birth variables in the raw data set. The variables have two versions, which are the 1979 version and the 1981 version. We only used the 1979 data and did a consistency check of those years and flag the inconsistent observations. 

```{r dob-tidy}
## tidy the date of birth data
dob_tidy <- new_data_qnames %>%
  dplyr::select(CASEID_1979,
         starts_with("Q1-3_A~")) %>%
  mutate(dob_year = case_when(
                    # if the years recorded in both sets match, take 79 data
                    `Q1-3_A~Y_1979` == `Q1-3_A~Y_1981` ~ `Q1-3_A~Y_1979`,
                    # if the year in the 81 set is missing, take the 79 data
                    is.na(`Q1-3_A~Y_1981`) ~ `Q1-3_A~Y_1979`,
                    # if the sets don't match for dob year, take the 79 data
                    `Q1-3_A~Y_1979` != `Q1-3_A~Y_1981` ~ `Q1-3_A~Y_1979`),
        dob_month = case_when(
                    # if months recorded in both sets match, take 79 data
                    `Q1-3_A~M_1979` == `Q1-3_A~M_1981` ~ `Q1-3_A~M_1979`,
                    # if month in 81 set is missing, take the 79 data
                    is.na(`Q1-3_A~M_1981`) ~ `Q1-3_A~M_1979`,
                    # if sets don't match for dob month, take the 79 data
                    `Q1-3_A~M_1979` != `Q1-3_A~M_1981` ~ `Q1-3_A~M_1979`),
        # flag if there is a conflict between dob recorded in 79 and 81
        dob_conflict = case_when(     
                      (`Q1-3_A~M_1979` != `Q1-3_A~M_1981`) & !is.na(`Q1-3_A~M_1981`)
                      ~ TRUE,
                      (`Q1-3_A~Y_1979` != `Q1-3_A~Y_1981`) & !is.na(`Q1-3_A~Y_1981`)
                      ~ TRUE,
                      (`Q1-3_A~Y_1979` == `Q1-3_A~Y_1981`) & 
                      (`Q1-3_A~M_1979` == `Q1-3_A~M_1981`) ~ FALSE,
                      is.na(`Q1-3_A~M_1981`) | is.na(`Q1-3_A~Y_1981`) ~ FALSE)) %>%
  dplyr::select(CASEID_1979,
         dob_month,
         dob_year,
         dob_conflict)
```


For `gender` and `race`, we only renamed these variables. 

```{r demog-tidy}
## tidy the gender and race variables
demog_tidy <- categories_qnames %>%
  dplyr::select(CASEID_1979,
         SAMPLE_RACE_78SCRN,
         SAMPLE_SEX_1979) %>%
  rename(gender = SAMPLE_SEX_1979,
         race = SAMPLE_RACE_78SCRN)
```

The `highest grade completed` came with several version in each year. We chose the revised May data because the May data seemed to have less missing and presumably the revised data has been checked. However, there was no revised May data for 2012, 2014, 2016, and 2018 so we just used the ordinary May data. 

```{r tidy-grade}
# tidy the grade 
demog_education <- new_data_qnames %>%
  as_tibble() %>%
  # in 2018, the variable's name is Q3-4_2018, instead of HGC_2018
  rename(HGC_2018 = `Q3-4_2018`) %>%
  dplyr::select(CASEID_1979,
         starts_with("HGCREV"),
         "HGC_2012",
         "HGC_2014",
         "HGC_2016",
         "HGC_2018") %>%
  pivot_longer(!CASEID_1979,
               names_to = "var",
               values_to = "grade") %>%
  separate("var", c("var", "year"), sep = -4) %>%
  filter(!is.na(grade)) %>%
  dplyr::select(-var)
```

In the final data, we only used the highest grade completed ever and derived the year of when the highest grade completed its categorical value. Therefore, we wrangled the highest grade completed in each year to mutate these variables. 

```{r tidy-hgc}

## getting the highest year of completed education ever
highest_year <- demog_education %>%
  group_by(CASEID_1979) %>%
  mutate(hgc_i = max(grade)) %>%
  filter(hgc_i == grade) %>%
  filter(year == first(year)) %>%
  rename(yr_hgc = year) %>%
  dplyr::select(CASEID_1979, yr_hgc, hgc_i) %>%
  ungroup() %>%
  mutate('hgc' = ifelse(hgc_i == 0, "NONE", ifelse(hgc_i == 1, "1ST GRADE",
                 ifelse(hgc_i == 2, "2ND GRADE", ifelse(hgc_i == 3, "3RD GRADE",
                 ifelse(hgc_i >= 4 & hgc_i <= 12, paste0(hgc_i,"TH GRADE"),
                 ifelse(hgc_i == 13, "1ST YEAR COL",
                 ifelse(hgc_i == 14, "2ND YEAR COL",
                 ifelse(hgc_i == 15, "3RD YEAR COL",
                 ifelse(hgc_i == 95, "UNGRADED", 
                        paste0((hgc_i - 12), "TH YEAR COL")))))))))))
```

Finally, we join all the tidy variables in a data set called `full_demographics`.

```{r full-demog}
full_demographics <- full_join(dob_tidy, demog_tidy, by = "CASEID_1979") %>%
  full_join(highest_year, by = "CASEID_1979") %>%
  rename("id" = "CASEID_1979")

head(full_demographics)
```

### Tidying employment variables

The employment data comprises of three variables, i.e. `total hours of work per week`, `number of jobs that an individual has`, and `mean hourly wage`. For hours worked per week, initially only one version per job, no choice from 1979 to 1987 (QES-52A). From 1988 onward, when we had more options, we chose the variable for total hours including time spent working from home (QES-52D). However, 1993 did not have all the five D variables (the first one and the last one were missing), so we used QES-52A variable instead. In addition, 2008 only had jobs 1-4 for the QES-52D variable (whereas the other years had 1-5), so we just used these.

```{r tidy-hours}
# make a list for years where we used the "QES-52A"
year_A <- c(1979:1987, 1993)
#function to get the hour of work
get_hour <- function(year){
  if(year %in% year_A){
   temp <- new_data_qnames %>%
    dplyr::select(CASEID_1979,
            starts_with("QES-52A") &
              ends_with(as.character(year)))} 
  else{
    temp <- new_data_qnames %>%
    dplyr::select(CASEID_1979,
            starts_with("QES-52D") &
              ends_with(as.character(year)))} 
    temp %>% 
      pivot_longer(!CASEID_1979,
                 names_to = "job",
                 values_to = "hours_work") %>%
      separate("job", c("job", "year"), sep = -4) %>%
      mutate(job = paste0("job_", substr(job, 9, 10))) %>%
      rename(id = CASEID_1979)
}

# list to save the iteration result
hours <- list()
# getting the hours of work of all observations
for(ayear in c(1979:1994, 1996, 1998, 2000, 2002, 2004, 2006, 2008, 2010, 
               2012, 2014, 2016, 2018)) {
   hours[[ayear]] <- get_hour(ayear)
}
# unlist the hours of work
hours_all <- bind_rows(!!!hours)
```

The same algorithm was also deployed to tidy the rate of wage by year and by ID. The difference is that the hourly rate had only one version of each year. The hours of work and the hourly rate were then joined to calculate the number of jobs that an ID has and their mean hourly wage. Some observations had 0 in their hourly rate, which is considered as invalid value. Thus, their hourly rate set to be N.A.

```{r tidy-rate}
get_rate <- function(year) {
  new_data_qnames %>%
    dplyr::select(CASEID_1979,
            starts_with("HRP") &
              ends_with(as.character(year))) %>%
    pivot_longer(!CASEID_1979, names_to = "job", values_to = "rate_per_hour") %>%
    separate("job", c("job", "year"), sep = -4) %>%
    mutate(job = paste0("job_0", substr(job, 4, 4))) %>%
    rename(id = CASEID_1979)
}
rates <- list()
for(ayear in c(1979:1994, 1996, 1998, 2000, 2002, 2004, 2006, 2008, 2010, 
               2012, 2014, 2016, 2018)) {
   rates[[ayear]] <- get_rate(ayear)
}
rates_all <- bind_rows(!!!rates)
# join hours and rates variable
hours_wages <- left_join(rates_all, 
                         hours_all, 
                         by = c("id", "year", "job")) %>%
  # set the 0 value in rate_per_hour as NA 
  mutate(rate_per_hour = ifelse(rate_per_hour == 0, NA,
                                rate_per_hour))
head(hours_wages)
```

Since our ultimate goal is to calculate the mean hourly wage, the number of jobs is calculate based on the availability of the `rate_per_hour` information. For example, the number of jobs of ID 1, based on `hours_work`, is two. However, since the information of hourly rate of `job_02` is not available, the number of job is considered as 1. 

Further, we calculated the mean hourly wage for each ID in each year using a weighted mean with the hours of work as the weight. However, there are a lot of missing value in `hours_work` variable. In that case, we only calculated the mean hourly wage based on arithmetic/regular mean method. Hence, we created a new variable to flag whether the mean hourly wage is a weighted or a regular mean. Additionally, if an ID only had one job, we directly used their hourly wages information and flagged it as an arithmetic mean.

```{r}
# calculate number of jobs that a person has in one year
no_job <- hours_wages %>%
  filter(!is.na(rate_per_hour)) %>%
  group_by(id, year) %>%
  summarise(no_jobs = length(rate_per_hour))

# filter the observations with available rate per hour
eligible_wages <- hours_wages %>%
  filter(!is.na(rate_per_hour)) %>%
  left_join(no_job, by = c("id", "year")) 

# calculate the mean_hourly_wage
# flag1 = code 1 for weighted mean
# code 0 for arithmetic mean
mean_hourly_wage <- 
  eligible_wages %>%
  group_by(id, year) %>%
  #calculate the weighted mean if the number of jobs > 1
  mutate(wages = ifelse(no_jobs == 1, rate_per_hour/100,
                        weighted.mean(rate_per_hour, hours_work, na.rm = TRUE)/100)) %>%
  #give the flag if it the weighted mean
  mutate(flag1 = ifelse(!is.na(wages) & no_jobs != 1, 1,
                        0)) %>%
  #calculate the arithmetic mean for the na
  mutate(wages = ifelse(is.na(wages), mean(rate_per_hour)/100,
                        wages)) %>%
  group_by(id, year) %>%
  summarise(wages = mean(wages),
            total_hours = sum(hours_work),
            number_of_jobs = mean(no_jobs),
            flag1 = mean(flag1)) %>%
  mutate(year = as.numeric(year)) %>%
  ungroup() %>%
  rename(mean_hourly_wage = wages) %>%
  mutate(is_wm = ifelse(flag1 == 1, TRUE,
                        FALSE)) %>%
  dplyr::select(-flag1)

head(mean_hourly_wage, n = 10)
```

The `mean_hourly_wage` and `full_demographic` data are then joined. We also filtered the data to only have the cohort who completed the education up to 12th grade and participated at least five rounds in the survey and save it to an object called `wages_demog_hs`. 

```{r}
# join the wages information and the demographic information by case id.
wages_demog <- left_join(mean_hourly_wage, full_demographics, by="id")
# calculate the years in work force and the age of the subjects in 1979
wages_demog <- wages_demog %>%
  mutate(yr_hgc = as.numeric(yr_hgc)) %>%
  mutate(years_in_workforce = year - yr_hgc) %>%
  mutate(age_1979 = 1979 - (dob_year + 1900))
# filter only the id with high school education
wages_demog_hs <- wages_demog  %>% filter(grepl("GRADE", hgc))
# calculate the number of observation
keep_me <- wages_demog_hs %>%
  count(id) %>%
  filter(n > 4)
wages_demog_hs <- wages_demog_hs %>%
  filter(id %in% keep_me$id)
```

## Initial Data Analysis

According to @HuebnerMariannePhD2016Asat, Initial Data Analysis (IDA) is the step of inspecting and screening the data after being collected to ensure that the data is clean, valid, and ready to be deployed in the later formal statistical analysis. Moreover, @Chatfield1985TIEo argued that the two main objectives of IDA is data description, which is to assess the structure and the quality of the data; and model formulation without any formal statistical inference. 

In this paper, we conducted an IDA or a preliminary data analysis to assess the consistency of the data with the cohort information that is provided by the NLSY. In addition, we also aimed to find the anomaly in the wages values using this approach. We mainly used graphical summary to do the IDA using `ggplot2`[@ggplot2] and `brolgar` [@brolgar]. 

As stated previously, the respondents' ages ranged from 12 to 22 when first interviewed in 1979. Hence, we would like to validate whether all of the respondents were in this range. Additionally, the [NLSY](https://www.nlsinfo.org/content/cohorts/nlsy79/intro-to-the-sample/nlsy79-sample-introduction) also provided the number of the survey cohort by their gender (6,403 males and 6,283 females) and race (7,510 Non-Black/Non-Hispanic; 3,174 Black; 2,002 Hispanic). To validate this, we used the `full_demographic` i.e. the data with the survey years 1979 sample. Table \ref{tab:age-table} and Table \ref{tab:gender-race-table} suggest that the demographic data we had is consistent with the sample information in the database.

```{r age-table, echo = FALSE}
age_table <- yowie::demographic_nlsy79 %>%
  group_by(age_1979) %>%
  count(age_1979) 

kable(age_table,
      caption = "Age Distribution of the NLSY79 samples",
      col.names = c("Age", "Number of Sample")) %>%
  kable_styling(latex_options = "striped")
```


```{r gender-race-table, echo = FALSE}
gender_race_table <- yowie::demographic_nlsy79 %>%
  tabyl(gender, race) %>%
  adorn_totals(c("row", "col")) %>%
  adorn_percentages("row") %>%
  adorn_pct_formatting(digits = 2) %>%
  adorn_ns(position = "front") %>%
  mutate(gender = ifelse(gender == "MALE", "Male",
                         ifelse(gender == "FEMALE", "Female", "Total")))

kable(gender_race_table,
      caption = "Gender and Race Distribution of the NLSY79 Samples",
      col.names = c("Gender", "Hispanic", "Black", "Non-Black, Non-Hispanic", "Total")) %>%
  kable_styling(latex_options = "striped") %>%
  add_header_above(c(" " = 1, "Race" = 3, " " = 1))

```

```{r featureplot, echo = FALSE, fig.cap = "Two plots showing the distribution of the mean hourly wage. Plot A portrays the pattern of mean hourly wage of high school cohort from 1979 to 2018 of each ID in US Dollar; Plot B shows the distribution of their minimum, median, and maximum value. We can see that some IDs had an extremely high of wages and it made the distribution of the three features is extremely skewed.", fig.width=6, fig.height=4}

spag <- wages_demog_hs %>%
  ggplot(aes(x = year,
             y = mean_hourly_wage,
             group = id)) +
  geom_line(alpha = 0.1) +
  ggtitle("a)") +
  theme(plot.title = element_text(size = 10))


wages_demog_hs_tsibble <- as_tsibble(x = wages_demog_hs,
                    key = id,
                    index = year,
                    regular = FALSE)
wages_three_feat <- wages_demog_hs_tsibble %>%
  features(mean_hourly_wage, 
           feat_three_num
           )
wages_feat_long <- wages_three_feat %>%
  pivot_longer(c(min, med, max), names_to = "feature", values_to = "value")
 feature <- ggplot(wages_feat_long) +
  geom_density(aes(x = value, colour = feature, fill = feature), alpha = 0.3) +
   ggtitle("b)") +
   theme(plot.title = element_text(size = 10))
 
spag + feature
```


The next step is that we explored the mean hourly wage data, in this case, we only explored the wages data in `wages_demog_hs`. Figure \ref{fig:featureplot} conveys that there is clearly a problem in the mean hourly wage values. Figure \ref{fig:featureplot} A shows that some observations had an exceptionally high figure of wages, even more than US$10,000 per hour. In Figure \ref{fig:featureplot} B, we barely see any difference in the minimum, median, an maximum value of the wages since the distribution is heavily skewed to the right. Additionally, Table \ref{tab:summarytable} shows that the overall wages median of the cohort is only 7.2, while the mean is 11.87. It indicates that the data might contains a lot of extreme values. 



```{r summarytable, echo = FALSE}
kable(as.array(summary(wages_demog_hs$mean_hourly_wage)), 
      caption = "Summary Statistics of Wages of High School Data",
      col.names = c("Statistics", "Value")) %>%
  kable_styling(latex_options = "striped")
```


Further, we took 36 samples randomly from the data and plotted it as is seen in Figure \ref{fig:sampleplot}. It implies that not only that some observations earned an extremely high figures of wages, but some also had a reasonably fluctuate wages, for example the IDs in panel number 5, 7, and 11. The plot also implies that the samples had a different pattern of mean hourly wages. Some had a flat wages for years but had a sudden increase in a year than it went down again, while the other experienced a upsurge in their wage, for instance the IDs in panel 9. 

According to @MichaelRPergamit2001DWTN, one of the flaws of the NLSY79 employment data is that since the NLSY79 collect the information of the working hours since the last interview, it might be challenging for the respondents to track the within-job hours changes that happens between survey year, especially for the respondents with fluctuate working hours or whose job is seasonal. It even has been more challenging since 1994, where the respondents had to recall two years period. This shortcoming might also contribute on the fluctuation of one's wages data. 

```{r sampleplot, echo = FALSE, fig.cap="The mean hourly wages of some random samples are shown in twelve facets, three IDs per facet. It suggests that some IDs had a reasonably fluctuate wages.", fig.height=4, fig.width=5}

set.seed(20210225)

ggplot(wages_demog_hs_tsibble, 
       aes(x = year,
                y = mean_hourly_wage,
                group = id)) +
  geom_line(alpha = 0.7) +
  facet_sample() +
  theme(axis.text.x = element_text(angle = 10, size = 6)) +
  ylab("mean hourly wage") 
```

### Robust Linear Model for Noises Treatment

As it is seen from figure \ref{fig:sampleplot}, there are many spikes in the mean hourly wage data. As part of the IDA, which is the model formulation, we built a robust linear regression model to address this issue. The notion of robust linear regression is to yield an estimation that is robust to the influence of noise or contamination [@KollerManuel2016rARP]. It also aims to detect the contamination by weighting each observation based on how "well-behave" they are, known as robustness weight. Observations with lower robustness weight are suggested as an outliers by this method [@KollerManuel2016rARP]. 

In this paper, we built the model using the `rlm` function from `MASS` package [@mass]. We set the `mean_hourly_wage` and `year` as the dependent and predictor respectively. Furthermore, we used M-Estimation with Huber weighting where the observation with small residual get a weight of 1, while the larger the residual, the smaller the weight (less than 1) [@rlm]. 

Since we worked with longitudinal data, we should built the model for each ID, instead of the overall data. The robust mixed model is actually the best model to be employed in this case. However, this method is too computationally and memory expensive, especially for a large data set, like the NLSY79 data. Thus, the model for each ID is built utilizing the `nest` and `map` function from `tidyr` [@tidyr] and `purrr` [@purrr] respectively. 

The challenging part of detecting the anomaly using the robustness weight is to determine the threshold of the weight where the observations considered as outliers. Moreover, it should be noted that not all the outliers is due to an error, instead it might be that one had a reasonably increasing or decreasing wages. To, minimize the risk of being mistakenly regard an outlier as an error outlier, we have simulated some threshold and study the behavior of the spikes in each threshold. We found that 0.3 is the most reasonable value to be the threshold to minimize the risk of that drawback because it still capture the sensible spikes in the data. After deciding the threshold, we flagged the observations with the weight less than 0.3, and imputed their mean hourly wage with the models' predicted value. 


```{r rlm, cache=TRUE, warning = FALSE, message = FALSE}
 
# nest the data by id to build a robust linear model
by_id <- wages_demog_hs %>%
  dplyr::select(id, year, mean_hourly_wage) %>%
  group_by(id) %>%
  nest()

# build a robust linear model
id_rlm <- by_id %>%
  mutate(model = map(.x = data,
                     .f = function(x){
                       rlm(mean_hourly_wage ~ year, data = x)
                     }))
# extract the property of the regression model
id_aug <- id_rlm %>%
  mutate(augmented = map(model, broom::augment)) %>%
  unnest(augmented)

# extract the weight of each observation
id_w <- id_rlm %>%
  mutate(w = map(.x = model,
                 .f = function(x){
                   x$w
                 })) %>%
  unnest(w) %>%
  dplyr::select(w)

# bind the property of each observation with their weight
id_aug_w <- cbind(id_aug, id_w) %>%
  dplyr::select(`id...1`,
                year,
                mean_hourly_wage,
                .fitted,
                .resid,
                .hat,
                .sigma,
                w) %>%
  rename(id = `id...1`)

# if the weight < 1, the mean_hourly_wage is replaced by the model's fitted/predicted value.
# and add the flag whether the observation is predicted value or not.
# since the fitted value is sometimes <0, and wages value could never be negative,
# we keep the mean hourly wage value even its weight < 1.

wages_rlm_dat <- id_aug_w %>%
  mutate(wages_rlm = ifelse(w < 0.3  & .fitted >= 0, .fitted,
                            mean_hourly_wage)) %>%
  mutate(is_pred = ifelse(w < 0.3 & .fitted >= 0, TRUE,
                          FALSE)) %>%
  dplyr::select(id, year, wages_rlm, is_pred)

# join back the `wages_rlm_dat` to `wages_demog_hs`

wages_demog_hs <- left_join(wages_demog_hs, wages_rlm_dat, by = c("id", "year"))

```

Figure \ref{fig:comppict} A shows that after imputing the "error outliers" with the models' predicted value, the highest wages value has decreased to be around US$250. The spikes were still observed, but are not as extreme as the original data set. In Figure \ref{fig:comppict} B) although the distributions of the features are still positively skewed, we can still examine it clearly the difference shape of those features. The minimum value is heavily skewed, means that most the subjects have a small minimum value of wages, but there are still extreme cases where their minimum wages was extremely higher than others. Moreover, these cases had a minimum wages that is higher than others' maximum wages. 

Furthermore, the robust linear regression has reduce the level of noise in the data set as is seen in Figure \ref{fig:compare}. The figure also implies that after the treatment, the fluctuation can still be observed in the data and only the large spikes, which are considered as "error outliers", are eliminated from the data. Hence, the model results a data set with the reasonable degree of fluctuation.

```{r comppict, echo = FALSE, fig.cap = "The distribution of the mean hourly wage after treating the extreme values. Plot A portrays the pattern of mean hourly wage of high school cohort from 1979 to 2018 of each ID in US Dollar; Plot B shows the distribution of their minimum, median, and maximum value. We can see that some observations still had reasonbaly higher wages than the others. The minimum, median, and maximum distribution is positively skewed, where some IDs' have a minimum wages that is higher than others' maximum wages.", fig.width=6, fig.height=4}

spag2 <- wages_demog_hs %>%
  ggplot(aes(x = year,
             y = wages_rlm,
             group = id)) +
  geom_line(alpha = 0.1) +
  ggtitle("a)") +
  theme(plot.title = element_text(size = 10))

wages_hs2020_rlm <- as_tsibble(x = wages_demog_hs,
                    key = id,
                    index = year,
                    regular = FALSE)
wages_three_feat_rlm <- wages_hs2020_rlm %>%
  features(wages_rlm, 
           feat_three_num
           )
wages_feat_long_rlm <- wages_three_feat_rlm %>%
  pivot_longer(c(min, med, max), names_to = "feature", values_to = "value")

feature2 <- ggplot(wages_feat_long_rlm) +
  geom_density(aes(x = value, colour = feature, fill = feature), alpha = 0.3) +
  ggtitle("b)") +
  theme(plot.title = element_text(size = 10))
 
spag2 + feature2
```

```{r compare-data, echo = FALSE}
set.seed(20210228)

sample_id <- sample(unique(wages_demog_hs$id), 20)
sample <- subset(wages_demog_hs, id %in% sample_id)

wages_compare <- sample %>%
  dplyr::select(id, year, mean_hourly_wage, wages_rlm) %>%
  rename(mean_hourly_wage_rlm = wages_rlm) %>%
  pivot_longer(c(-id, -year), names_to = "type", values_to = "wages")
```


```{r compare, echo = FALSE, fig.cap="Comparison between the original and the treated mean hourly wage. The orange line portray the original value of mean hourly wage, while the turquoise line display the mean hourly wages value after the extreme values imputed with the robust linear model's prediction value. We can see that some extreme spikes has been reduced by the model.", fig.height=4, fig.width=5}
ggplot(wages_compare) +
  geom_line(aes(x = year,
                y = wages,
                colour = type,
                linetype = type),
            alpha = 1) +
  geom_point(aes(x = year,
                y = wages,
                colour = type),
            alpha = 0.5,
            size = 0.5) +
  theme(axis.text.x = element_text(angle = 10, size = 5),
        legend.position = "bottom") +
  facet_wrap(~id)


```

Finally, we saved the imputed data and set the appropriate data type for the variables. We also saved the NLSY79 cohort's demographic information and the high school dropout cohort in a separate data sets. Here, we defined high school dropouts as respondents who only completed either $9^{th}$, $10^{th}$, $11^{th}$ grade, or who completed $12^{th}$ when their age are at least 19 years old (means that these IDs being dropped out in certain year, but they returned back to high school to complete it). 

The complete flow from the raw data to these data set is displayed in Figure \ref(fig:flowchart).

```{r}
# select out the old value of mean hourly wage and change it with the wages_rlm value
wages_demog_hs <- wages_demog_hs %>%
  dplyr::select(-mean_hourly_wage) %>%
  rename(mean_hourly_wage = wages_rlm)

# rename and select the wages in tidy
wages_hs2020 <- wages_demog_hs %>%
  dplyr::select(id, year, mean_hourly_wage, age_1979, gender, race, hgc, hgc_i, yr_hgc,
                number_of_jobs, total_hours, is_wm, is_pred) %>%
  mutate(hgc = as.factor(hgc),
         year = as.integer(year),
         age_1979 = as.integer(age_1979),
         yr_hgc = as.integer(yr_hgc),
         number_of_jobs = as.integer(number_of_jobs))

# Create a data set for demographic variables
demographic_nlsy79 <- full_demographics %>%
  mutate(age_1979 = 1979 - (dob_year + 1900)) %>%
  dplyr::select(id,
         age_1979,
         gender,
         race,
         hgc,
         hgc_i,
         yr_hgc) %>%
  mutate(age_1979 = as.integer(age_1979),
         hgc = as.factor(hgc),
         yr_hgc = as.integer(yr_hgc))

# Create a data set for the high school dropouts cohort
wages_hs_dropout <- wages_hs2020 %>%
  mutate(dob = 1979 - age_1979,
         age_hgc = yr_hgc - dob) %>%
  filter((hgc %in% c("9TH GRADE",
                     "10TH GRADE",
                     "11TH GRADE")) |
          (hgc == "12TH GRADE" &
              age_hgc > 19)) %>%
  filter(age_1979 <= 17,
         gender == "MALE") %>%
  dplyr::select(-dob,
         -age_hgc)

```




```{r nrow, echo=FALSE}
a = nrow(categories_qnames)
b = nrow(full_demographics)
d = eligible_wages %>%
  group_by(id) %>%
  count(id) %>%
  nrow()
n_hgc = wages_hs2020 %>%
  group_by(id) %>%
  count(id) %>%
  nrow()
n_obs_hgc = nrow(wages_hs2020)
n_obs_hgc_pred = filter(wages_hs2020, is_pred == TRUE) %>%
  nrow()

n_do = wages_hs_dropout %>%
  group_by(id) %>%
  count(id) %>%
  nrow()
n_obs_do = nrow(wages_hs_dropout)
n_obs_do_pred = filter(wages_hs_dropout, is_pred == TRUE) %>%
  nrow()
```


```{r flowchart, echo=FALSE, fig.cap="The stages of data filtering from the raw data to get three datasets that are contained in an R package called yowie, n means the number of ID, while n_obs means the number of observations.", fig.height=3, fig.width=3}

fc <- grViz("digraph flowchart {
      node [fontname = Helvetica, shape = rectangle]        
      tab1 [label = '@@1']
      tab2 [label = '@@2']
      tab3 [label = '@@3']
      tab4 [label = '@@4']
      tab5 [label = '@@5']
      tab6 [label = '@@6']
      tab7 [label = '@@7']

      tab1 -> tab2;
      tab1 -> tab3;
      tab1 -> tab4 -> tab5 -> tab6;
      tab5 -> tab7;
      tab6 -> tab7;
      tab2 -> tab7
      }

      [1]: paste0('NLSY79, n = ', a)
      [2]: paste0('Extract demographic variable, n = ', b)
      [3]: paste0('Exclude ', a - d, ' IDs whose hourly rate is missing')
      [4]: paste0('Eligible ID, n = ', d)
      [5]: paste0('Cohort whose hgc is up to 12th grade and \\n participated at least 5 years in the survey, \\n n = ', n_hgc, ', n_obs = ', n_obs_hgc, ' \\n (', n_obs_hgc_pred, ' observations are predicted value)')
      [6]: paste0('High school dropouts cohort, \\n n = ', n_do, ', n_obs = ', n_obs_do, ' \\n (', n_obs_do_pred, ' observations are predicted value)')
      [7]: 'yowie Package'
      ",
      height = 200)

fc
```



# Exploratory Data Analysis


# Summary and Discussion

Wild caught data is often not tidy and clean. IDA, as a way to assess data quality should be performed and most importantly documented to avoid bias publication. In this paper, we performed an IDA on the NLSY79 data, specifically the wages data. We chose this data set because it play an important role in various discipline of research, especially the life course research. Getting the data from the database is pretty straightforward. However, it cannot be directly deployed to the analysis since the form is untidy. Data exploration also found some anomalies in the wages data where some IDs had an extremely high wages and large spikes. Hence, we performed data wrangling to tidy the data and robust linear regression model for each ID to find and treat the anomalies. We used the robustness weight of  less than 0.5 as threshold of the wages considered as outliers. 

- From this IDA, we learned that the open data is not only the matter of opennes, but also how that data could be analyzed flexibly with a tidy dataset. Hence, our recommendation that the database for every open data should be built to produce a tidy data. 

- For the future study, the room for improvement: linear mixed model and more sophisticated method to determine the threshold?

- Data provider should provide validation rules for data user


