@Manual{tidyr,
    title={tidyr: Tidy Messy Data},
    author={Hadley Wickham},
    year={2020},
    note={R package version 1.1.2},
    url={https://CRAN.R-project.org/package=tidyr}
  }

@Manual{dplyr,
    title = {dplyr: A Grammar of Data Manipulation},
    author = {Hadley Wickham and Romain François and Lionel {
             Henry} and Kirill Müller},
    year = {2020},
    note = {R package version 1.0.2},
    url = {https://CRAN.R-project.org/package=dplyr}
  }

@Manual{stringr,
    title = {stringr: Simple, Consistent Wrappers for Common String Operations},
    author = {Hadley Wickham},
    year = {2019},
    note = {R package version 1.4.0},
    url = {https://CRAN.R-project.org/package=stringr}
  }

@article{HuebnerMariannePhD2016Asat,
issn = {0022-5223},
abstract = {Abstract Initial data analysis is conducted independently of the analysis needed to address the research questions. Shortcomings in these first steps may result in inappropriate statistical methods or incorrect conclusions. We outline a framework for initial data analysis and illustrate the impact of initial data analysis on research studies. Examples of reporting of initial data analysis in publications are given. A systematic and careful approach to initial data analysis is needed as good research practice.},
journal = {The Journal of thoracic and cardiovascular surgery},
pages = {25--27},
volume = {151},
publisher = {Elsevier Inc},
number = {1},
year = {2016},
title = {A systematic approach to initial data analysis is good research practice},
copyright = {The American Association for Thoracic Surgery},
language = {eng},
address = {United States},
author = {Huebner, Marianne, PhD and Vach, Werner, Dr rer. nat and le Cessie, Saskia, PhD},
keywords = {Cardiothoracic Surgery ; data screening ; data cleaning ; initial data analysis ; Data Collection - statistics & numerical data ; Data Interpretation, Statistical ; Reproducibility of Results ; Humans ; Biomedical Research - statistics & numerical data ; Biomedical Research - methods ; Models, Statistical ; Research Design - statistics & numerical data ; Analysis ; Information management ; Index Medicus ; Abridged Index Medicus},
}

@article{Chatfield1985TIEo,
issn = {0035-9238},
abstract = {The initial examination of data (abbreviated IDA) is a valuable stage of most statistical investigations, not only for scrutinizing and summarizing data, but also for model formulation. Several examples are presented to illustrate the benefits of IDA, particularly that IDA may be all that is necessary or desirable. In particular, a re-analysis of the notorious teaching styles data produces completely different conclusions to earlier studies. A critical comparison is made between IDA and Tukey's exploratory data analysis approach. Some reasons why IDA is often neglected or undervalued are discussed and countered. Some implications for the teaching of Statistics are considered.},
journal = {Journal of the Royal Statistical Society. Series A. General},
pages = {214--253},
volume = {148},
publisher = {Royal Statistical Society},
number = {3},
year = {1985},
title = {The Initial Examination of Data},
copyright = {Copyright 1985 Royal Statistical Society},
language = {eng},
address = {London},
author = {C. Chatfield},
keywords = {Outliers ; Datasets ; Statistical variance ; Data analysis ; Applied statistics ; Inference ; Mathematics education ; Descriptive statistics ; Statistics ; Modeling ; computer packages ; graphical procedures ; exploratory data analysis ; descriptive statistics ; model formulation ; teaching statistics ; outliers ; teaching styles data ; data editing ; significance tests ; errors},
}

@Manual{brolgar,
    title = {brolgar: BRowse Over Longitudinal data Graphically and Analytically in R},
    author = {Nicholas Tierney and Di Cook and Tania Prvan},
    year = {2020},
    note = {R package version 0.0.6.9100},
    url = {https://github.com/njtierney/brolgar},
  }

@Book{ggplot2,
    author = {Hadley Wickham},
    title = {ggplot2: Elegant Graphics for Data Analysis},
    publisher = {Springer-Verlag New York},
    year = {2016},
    isbn = {978-3-319-24277-4},
    url = {https://ggplot2.tidyverse.org},
  }

@article{KollerManuel2016rARP,
issn = {1548-7660},
abstract = {As any real-life data, data modeled by linear mixed-effects models often contain outliers or other contamination. Even little contamination can drive the classic estimates far away from what they would be without the contamination. At the same time, datasets that require mixed-effects modeling are often complex and large. This makes it difficult to spot contamination. Robust estimation methods aim to solve both problems: to provide estimates where contamination has only little influence and to detect and flag contamination. We introduce an R package, robustlmm, to robustly fit linear mixed-effects models. The package's functions and methods are designed to closely equal those offered by lme4, the R package that implements classic linear mixed-effects model estimation in R. The robust estimation method in robustlmm is based on the random effects contamination model and the central contamination model. Contamination can be detected at all levels of the data. The estimation method does not make any assumption on the data's grouping structure except that the model parameters are estimable. robustlmm supports hierarchical and non-hierarchical (e.g., crossed) grouping structures. The robustness of the estimates and their asymptotic efficiency is fully controlled through the function interface. Individual parts (e.g., fixed effects and variance components) can be tuned independently. In this tutorial, we show how to fit robust linear mixed-effects models using robustlmm, how to assess the model fit, how to detect outliers, and how to compare different fits.},
journal = {Journal of statistical software},
pages = {1--24},
volume = {75},
publisher = {Foundation for Open Access Statistics},
number = {6},
year = {2016},
title = {robustlmm: An R Package for Robust Estimation of Linear Mixed-Effects Models},
language = {eng},
author = {Koller, Manuel},
keywords = {random effect ; hierarchical model ; mixed-effects model ; crossed ; ANOVA ; robust statistics},
}



@ONLINE{rlm,
  author = {{UCLA: Statistical Consulting Group}},
  title = {Robust Regression | R Data Analysis Examples},
  month = FEB,
  year = {2021},
  url = {https://stats.idre.ucla.edu/r/dae/robust-regression/}
}


@Book{mass,
    title = {Modern Applied Statistics with S},
    author = {W. N. Venables and B. D. Ripley},
    publisher = {Springer},
    edition = {Fourth},
    address = {New York},
    year = {2002},
    note = {ISBN 0-387-95457-0},
    url = {http://www.stats.ox.ac.uk/pub/MASS4},
  }


@Manual{purrr,
    title = {purrr: Functional Programming Tools},
    author = {Lionel Henry and Hadley Wickham},
    year = {2020},
    note = {R package version 0.3.4},
    url = {https://CRAN.R-project.org/package=purrr},
  }


@book{DasuTamraparni2003Edma,
series = {Wiley series in probability and statistics},
abstract = {TAMRAPARNI DASU, PhD, and THEODORE JOHNSON, PhD, are both members of the technical staff at AT&T Labs-Research in Florham Park, New Jersey.},
publisher = {WILEY},
booktitle = {<h>Exploratory data mining and data cleaning</h>},
isbn = {9780471448358},
year = {2003},
title = {Exploratory data mining and data cleaning},
language = {eng},
address = {Hoboken},
author = {Dasu, Tamraparni and Johnson, Theodore},
keywords = {Probability & Statistics ; General ; Mathematics ; Electronic data processing ; Data preparation ; Data mining ; Quality control},
}

@article{WickhamHadley2014TD,
issn = {1548-7660},
abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
journal = {Journal of statistical software},
pages = {1--23},
volume = {59},
publisher = {Foundation for Open Access Statistics},
number = {10},
year = {2014},
title = {Tidy Data},
language = {eng},
author = {Wickham, Hadley},
}


@incollection{eliznlsy,
  author       = {Elizabeth C. Cooksey},
  title        = {Using the National Longitudinal Surveys of Youth (NLSY) to Conduct Life Course Analyses},
  booktitle    = {Handbook of Life Course Health Development},
  publisher    = {Springer},
  year         = 2017,
  editor       = {Neal Halfon, Christoper B. Forrest, Richard M. Lerner, Elaine M. Faustman},
  doi          = {https://doi.org/10.1007/978-3-319-47143-3_23},
  pages        = {561-577},
  address      = {Cham},
  month        = 11
}


@article{MichaelRPergamit2001DWTN,
issn = {0895-3309},
abstract = {This article describes the design features and topical coverage of the National Longitudinal Surveys (NLS). The NLS are perhaps the oldest and most widely used panel surveys of individuals in the United States. These surveys were started in the mid-1960s to exam employment issues faced by different cohorts of the U.S. population. Since then, the NLS surveys have expanded to include two new cohorts of youth. Survey topic areas include employment, education, training, family relationships, financial well-being, and health. Information on data access is also provided.},
journal = {The Journal of economic perspectives},
pages = {239--253},
volume = {15},
publisher = {American Economic Association},
number = {2},
year = {2001},
title = {Data Watch: The National Longitudinal Surveys},
copyright = {Copyright 2001 American Economic Association},
language = {eng},
address = {Nashville},
author = {Michael R. Pergamit and Charles R. Pierret and Donna S. Rothstein and Jonathan R. Veum},
keywords = {Job training ; Economic theory ; Employment ; Men ; Economic surveys ; Labor markets ; Spouses ; Longitudinal studies ; Features ; Children ; School surveys ; Employment surveys ; Surveys ; Educational surveys ; United States ; Health ; Family ; Layoffs ; Labor market ; Population ; Labor force ; Employment interviews ; Polls & surveys},
}

@article{HuebnerMarianne2020Haar,
issn = {1471-2288},
abstract = {In the data pipeline from the data collection process to the planned statistical analyses, initial data analysis (IDA) typically takes place between the end of the data collection and do not touch the research questions. A systematic process for IDA and clear reporting of the findings would help to understand the potential shortcomings of a dataset, such as missing values, or subgroups with small sample sizes, or shortcomings in the collection process, and to evaluate the impact of these shortcomings on the research results. A clear reporting of findings is also relevant when making datasets available to other researchers. Initial data analyses can provide valuable insights into the suitability of a data set for a future research study. Our aim was to describe the practice of reporting of initial data analyses in observational studies in five highly ranked medical journals with focus on data cleaning, screening, and reporting of findings which led to a potential change in the analysis plan.
This review was carried out using systematic search strategies with eligibility criteria for articles to be reviewed. A total of 25 papers about observational studies were selected from five medical journals published in 2018. Each paper was reviewed by two reviewers and IDA statements were further discussed by all authors. The consensus was reported.
IDA statements were reported in the methods, results, discussion, and supplement of papers. Ten out of 25 papers (40%) included a statement about data cleaning. Data screening statements were included in all articles, and 18 (72%) indicated the methods used to describe them. Item missingness was reported in 11 papers (44%), unit missingness in 15 papers (60%). Eleven papers (44%) mentioned some changes in the analysis plan. Reported changes referred to missing data treatment, unexpected values, population heterogeneity and aspects related to variable distributions or data properties.
Reporting of initial data analyses were sparse, and statements on IDA were located throughout the research articles. There is a lack of systematic reporting of IDA. We conclude the article with recommendations on how to overcome shortcomings in the practice of IDA reporting in observational studies.},
journal = {BMC medical research methodology},
pages = {61--61},
volume = {20},
publisher = {BioMed Central},
number = {1},
year = {2020},
title = {Hidden analyses: a review of reporting practice and recommendations for more transparent reporting of initial data analyses},
copyright = {2020. This work is licensed under http://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
language = {eng},
address = {England},
author = {Huebner, Marianne and Vach, Werner and le Cessie, Saskia and Schmidt, Carsten Oliver and Lusa, Lara},
keywords = {Variables ; Data collection ; Medical research ; Data analysis ; Journals ; Index Medicus ; Reporting ; Observational studies ; Initial data analysis ; STRATOS initiative},
organization = {Topic Group “Initial Data Analysis” of the STRATOS Initiative (STRengthening Analytical Thinking for Observational Studies, http://www.stratos-initiative.org)},
}


@online{opendata,
  author = {{Open Knowledge Foundation}},
  title = {Open Definition. Defining Open in Open Data, Open Content, and Open Knowledge},
  url = {http://opendefinition.org/od/2.1/en/},
  urldate = {2021-03-03}
}


@book{SingerJudithD2003Alda,
abstract = {In this book, [the authors] use concrete examples and careful explanation to demonstrate how research questions about change and event occurrence can be addressed with longitudinal data. In doing so, [they] reveal research opportunities unavailable in the world of cross-sectional data. ... The book is divided into two major parts: individual growth modelling in the first half, survival analysis in the second. Throughout each half, [are stressed] the important connections between the methods. Each half has its own introduction that 1) discusses when the method might be used; 2) distinguishes among the different types of research questions in that domain and 3) identifies the major statistical features of empirical studies that lend themselves to the specified analyses. Both types of analyses require a sensible metric for clocking time. But in growth modelling ... multiple waves of data [are needed] and an outcome that changes systematically whereas in survival analysis, [the reader] must clearly identify the beginning of time and the criteria used to assess event occurrence. Subsequent chapters in each half of the book walk [the reader] through the details of analysis. Each begins with a chapter on data description and exploratory analysis, followed by a detailed discussion of model specification, model fitting, and parameter interpretation. Having introduced a basic model, [the authors] consider extensions. Because it is easier to understand the path that winds through the book only after important issues relevant for each half have been introduced, [they] defer discussion of each half's outline to its associated introductory chapter. (DIPF/Orig.).},
publisher = {Oxford Univ. Pr},
booktitle = {Applied longitudinal data analysis},
isbn = {0195152964},
year = {2003},
title = {Applied longitudinal data analysis: Modeling change and event occurrence},
language = {eng},
address = {Oxford u.a},
author = {Singer, Judith D and Willett, John B},
keywords = {Modellbildung ; Längsschnittuntersuchung ; Beispiel ; Datenanalyse ; Forschungsdesign ; Statistik ; Methodologie ; Geschichte (Histor) ; Epidemiology ; Public Health ; Longitudinal method ; Social sciences ; Research},
}
